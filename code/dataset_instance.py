from random import Random

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
from util import pad_custom_color, decode_label, remove_prefix, print, similarity, generate_random_string, crop_white
from model import decode_batch_predictions


class OCRDataset:
    def __init__(self, data_dirs, img_width, img_height, train_data_amount=0.9, dataset_limit=None, charset=None, transform=None):
        self.data_dirs = data_dirs
        self.img_width = img_width
        self.img_height = img_height
        self.train_data_amount = train_data_amount
        self.dataset_limit = dataset_limit
        self.transform = transform

        self.train_losses = []
        self.val_losses = []
        self.cumulative_train_times = []
        self.validation_percentages = []

        self._load_dataset(charset)
        self._preprocess()
        self._split_dataset()

    def _load_dataset(self, charset):
        # Load all image paths, sort using a random key generated by the fixed RNG
        # This is done to ensure random order of images and non-biased splits to training/validation datasets
        # The seed must stay constant over the course of training a model in order to not compromise validation dataset
        rng = Random(42)
        self.all_images = [img for d in self.data_dirs for img in d.glob("*.png")]
        rng.shuffle(self.all_images)
        # Extract labels from image filenames (using remove_prefix)
        self.all_labels = [remove_prefix(img.stem) for img in self.all_images]
        # Determine the set of characters
        if charset is None:
            characters = set(char for label in self.all_labels for char in label)
        else:
            characters = set(char for char in charset)
        self.characters = sorted(list(characters))

        print(f"Images found: {len(self.all_images)}")
        print(f"Unique characters ({len(self.characters)}): {self.characters}")

        # Maximum label length in the dataset
        self.max_length = max(len(label) for label in self.all_labels)

    def _preprocess(self):
        # Reserve 0 for padding
        self.char_to_num = {char: i + 1 for i, char in enumerate(self.characters)}
        self.num_to_char = {i: char for char, i in self.char_to_num.items()}
        self.num_to_char[0] = '∅'  # Padding character

        # Tokenize labels
        self.all_labels = [
            [self.char_to_num.get(char, 0) for char in label] for label in self.all_labels
        ]

    def _split_dataset(self):
        total_size = len(self.all_images)
        train_size = int(total_size * self.train_data_amount)
        if self.dataset_limit is not None:
            train_limit = self.dataset_limit
            validation_limit = int(self.dataset_limit * self.train_data_amount)
            self.train_images = self.all_images[:train_size][:train_limit]
            self.train_labels = self.all_labels[:train_size][:train_limit]
            self.valid_images = self.all_images[train_size:][:validation_limit]
            self.valid_labels = self.all_labels[train_size:][:validation_limit]
        else:
            self.train_images = self.all_images[:train_size]
            self.train_labels = self.all_labels[:train_size]
            self.valid_images = self.all_images[train_size:]
            self.valid_labels = self.all_labels[train_size:]

    class _SplitDataset(Dataset):
        def __init__(self, images, labels, img_width, img_height, transform):
            self.images = images
            self.labels = labels
            self.img_width = img_width
            self.img_height = img_height
            self.transform = transform

        def __len__(self):
            return len(self.images)

        def __getitem__(self, idx):
            img_path = self.images[idx]
            label = self.labels[idx]

            image = plt.imread(img_path)  # (H, W) • (H, W, 3) • (H, W, 4)
            # convert to grayscale if needed
            if image.ndim == 3:  # RGB or RGBA
                if image.shape[2] == 4:  # strip alpha channel
                    image = image[..., :3]
                # weighted average luminance
                image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])
                # image is now (H, W)
            # normalise & shape to [C, H, W]
            if image.dtype == np.uint8:
                image = image.astype(np.float32) / 255.0
            else:
                image = image.astype(np.float32)
            image = torch.from_numpy(image).unsqueeze(0)  # [1, H, W]
            image = crop_white(image)
            image = pad_custom_color(image, self.img_width, self.img_height)
            if self.transform:
                image = self.transform(image)

            label_length = len(label)
            return {
                'image': image,  # [1, H, W]
                'label': torch.tensor(label, dtype=torch.long),
                'label_length': torch.tensor(label_length, dtype=torch.long)
            }

    @staticmethod
    def collate_fn(batch):
        images = [item['image'] for item in batch]
        labels = [item['label'] for item in batch]
        label_lengths = [item['label_length'] for item in batch]

        images = torch.nn.utils.rnn.pad_sequence(images, batch_first=True, padding_value=1)
        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)
        label_lengths = torch.stack(label_lengths)

        return {
            'image': images,
            'label': labels,
            'label_length': label_lengths
        }

    def get_train_dataloader(self, batch_size=16, shuffle=True, num_workers=4, pin_memory=True):
        train_dataset = OCRDataset._SplitDataset(
            self.train_images, self.train_labels, self.img_width, self.img_height, self.transform
        )
        return DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=shuffle,
            collate_fn=OCRDataset.collate_fn,
            num_workers=num_workers,
            pin_memory=pin_memory,
        )

    def get_validation_dataloader(self, batch_size=16, shuffle=False, num_workers=4, pin_memory=True):
        valid_dataset = OCRDataset._SplitDataset(
            self.valid_images, self.valid_labels, self.img_width, self.img_height, self.transform
        )
        return DataLoader(
            valid_dataset,
            batch_size=batch_size,
            shuffle=shuffle,
            collate_fn=OCRDataset.collate_fn,
            num_workers=num_workers,
            pin_memory=pin_memory,
        )

    def validate(self, dataloader, device):
        self.model.eval()
        total_loss = 0.0
        percentages = []
        with torch.no_grad():
            for batch in dataloader:
                images = batch['image'].to(device)
                labels = batch['label'].to(device)
                label_len = batch["label_length"].to(device)
                # Forward pass with loss computation.
                log_probs, loss = self.model(images, labels, label_len)
                total_loss += loss.mean().item()

                decoded_texts = decode_batch_predictions(log_probs, self.max_length, self.num_to_char)
                for i, text in enumerate(decoded_texts):
                    decoded_label = decode_label(self.num_to_char, labels[i])
                    match_percentage = similarity(text, decoded_label)
                    percentages.append(match_percentage)

        avg_percentage = sum(percentages) / len(percentages)
        self.validation_percentages.append(avg_percentage)
        avg_val_loss = total_loss / len(dataloader)
        return avg_val_loss, percentages

    def visualize_samples(self, num_samples=16):
        print("Displaying examples from the training set for user validation...")
        sample_dataset = OCRDataset._SplitDataset(
            self.train_images[:num_samples], self.train_labels[:num_samples], self.img_width, self.img_height,
            self.transform
        )
        sample_loader = DataLoader(sample_dataset, batch_size=num_samples, collate_fn=OCRDataset.collate_fn)
        batch = next(iter(sample_loader))
        images = batch['image']
        labels = batch['label']
        label_lengths = batch['label_length']

        grid_size = int(np.ceil(np.sqrt(num_samples)))
        fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size * 2, grid_size * 1.25))
        axes = axes.flatten()

        for idx in range(num_samples):
            if idx >= images.size(0):
                break
            img = images[idx].squeeze(0).numpy()
            decoded_label = decode_label(self.num_to_char, labels[idx])
            ax = axes[idx]
            ax.imshow(img, cmap="gray", extent=(0, img.shape[1], img.shape[0], 0))
            ax.set_title(f"{decoded_label} ({label_lengths[idx].item()})", fontsize=8)
            ax.axis("off")
            rect = Rectangle(
                (0, 0),
                img.shape[1],
                img.shape[0],
                linewidth=1,
                edgecolor='black',
                facecolor='none'
            )
            ax.add_patch(rect)

        plt.get_current_fig_manager().set_window_title('Training dataset samples')
        plt.tight_layout()
        plt.show()

    def visualize_predictions(self, model, device, epoch, dataset_name, num_samples=16):
        """Visualizes model predictions on a batch from the validation set."""
        model.eval()
        val_loader = self.get_validation_dataloader(batch_size=num_samples, shuffle=False, num_workers=0,
                                                    pin_memory=False)
        batch = next(iter(val_loader))
        images = batch['image'].to(device)
        labels = batch['label'].to(device)
        label_len = batch["label_length"].to(device)

        with torch.no_grad():
            log_probs, _ = model(images, labels, label_len)

        orig_texts = [decode_label(self.num_to_char, labels[i]) for i in range(len(labels))]
        decoded_texts = decode_batch_predictions(log_probs, self.max_length, self.num_to_char)

        n_cols = 4
        n_rows = (num_samples + n_cols - 1) // n_cols
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 1.25))
        if n_rows * n_cols > 1:
            axes = axes.flatten()
        else:
            axes = [axes]

        for i in range(num_samples):
            img = images[i].cpu().squeeze(0).numpy()
            predicted_text = decoded_texts[i]
            orig_text = orig_texts[i]
            match_percentage = similarity(predicted_text, orig_text)
            is_correct = predicted_text == orig_text
            color = 'green' if is_correct else 'red'
            title = f"Pred: {predicted_text}\nTrue: {orig_text}\nMatch: {match_percentage:.2f}%"
            ax = axes[i]
            ax.imshow(img, cmap="gray", extent=[0, img.shape[1], img.shape[0], 0])
            ax.set_aspect('equal')
            ax.set_title(title, fontsize=10, color=color)
            ax.axis("off")
            rect = Rectangle((0, 0), img.shape[1], img.shape[0],
                             linewidth=1, edgecolor='black', facecolor='none')
            ax.add_patch(rect)

        for j in range(num_samples, len(axes)):
            axes[j].axis("off")

        plt.tight_layout()
        prediction_filename = f'../models/{dataset_name}/results/epoch_{epoch + 1}_{generate_random_string(4)}.png'
        plt.savefig(prediction_filename)
        plt.close()

        # Plot loss history vs time
        cumulative_minutes = [t / 60.0 for t in self.cumulative_train_times]
        plt.figure(figsize=(10, 5))
        plt.plot(cumulative_minutes, self.train_losses, label='Training Loss')
        plt.plot(cumulative_minutes, self.val_losses, label='Validation Loss')
        plt.xlabel("Cumulative Training Time (minutes)")
        plt.ylabel("Loss")
        plt.xticks(np.arange(1, cumulative_minutes[-1] + 1, step=max(1, cumulative_minutes[-1] // 10)))
        plt.title("Cumulative Training Time vs. Loss")
        plt.legend()
        plt.grid(True)
        time_loss_filename = f'../models/{dataset_name}/results/loss_time_history_{epoch + 1}_{generate_random_string(4)}.png'
        plt.savefig(time_loss_filename)
        plt.close()

        # Plot percentage history vs epoch
        plt.figure(figsize=(10, 5))
        plt.plot(range(1, len(self.validation_percentages) + 1), self.validation_percentages, label='Average string similarity (%)')
        plt.title('Epoch vs. Similarity')
        plt.xlabel('Epoch')
        plt.xticks(np.arange(1, len(self.validation_percentages) + 1, step=max(1, len(self.validation_percentages) // 10)))
        plt.ylabel('Similarity')
        plt.ylim(0, 100)
        plt.legend()
        plt.grid(True)
        similarity_filename = f'../models/{dataset_name}/results/percentage_history_{epoch + 1}_{generate_random_string(4)}.png'
        plt.savefig(similarity_filename)
        plt.close()
